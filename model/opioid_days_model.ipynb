{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\liedt\\OneDrive\\Georgia Tech\\CSE 6242 Data and Visual Analytics\\Project\\model')\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import vtreat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import skopt\n",
    "import pickle\n",
    "from opioid_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file\n",
    "sqlite_file = 'DVADB/DVADB.db'\n",
    "\n",
    "# open a connection\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "sql = (\"\"\"\n",
    "SELECT npi_summary.npi\n",
    "    ,npi_summary.nppes_credentials\n",
    "    ,npi_summary.nppes_provider_gender\n",
    "    ,npi_summary.nppes_provider_city\n",
    "    ,npi_summary.nppes_provider_state\n",
    "    ,npi_summary.nppes_provider_country\n",
    "    ,npi_summary.specialty_description\n",
    "    ,npi_summary.total_claim_count\n",
    "    ,npi_summary.bene_count\n",
    "    ,npi_summary.opioid_claim_count\n",
    "    ,npi_summary.opioid_day_supply\n",
    "    ,npi_summary.opioid_bene_count\n",
    "    ,npi_summary.opioid_prescriber_rate\n",
    "    ,npi_summary.average_age_of_beneficiaries\n",
    "    ,npi_summary.beneficiary_age_less_65_count\n",
    "    ,npi_summary.beneficiary_age_65_74_count\n",
    "    ,npi_summary.beneficiary_age_75_84_count\n",
    "    ,npi_summary.beneficiary_age_greater_84_count\n",
    "    ,npi_summary.beneficiary_female_count\n",
    "    ,npi_summary.beneficiary_male_count\n",
    "    ,npi_summary.beneficiary_race_white_count\n",
    "    ,npi_summary.beneficiary_race_black_count\n",
    "    ,npi_summary.beneficiary_race_asian_pi_count\n",
    "    ,npi_summary.beneficiary_race_hispanic_count\n",
    "    ,npi_summary.beneficiary_race_nat_ind_count\n",
    "    ,npi_summary.beneficiary_race_other_count\n",
    "    ,npi_summary.beneficiary_nondual_count\n",
    "    ,npi_summary.beneficiary_dual_count\n",
    "    ,npi_summary.beneficiary_average_risk_score\n",
    "    ,Physicians_unique.Graduation_year\n",
    "    ,CASE\n",
    "        WHEN [graduation_year] BETWEEN '1952' AND '1977' THEN '1952-1977'\n",
    "        WHEN [graduation_year] BETWEEN '1978' AND '1987' THEN '1978-1987'\n",
    "        WHEN [graduation_year] BETWEEN '1988' AND '1997' THEN '1988-1997'\n",
    "        WHEN [graduation_year] BETWEEN '1998' AND '2007' THEN '1998-2007'\n",
    "        WHEN [graduation_year] BETWEEN '2008' AND '2018' THEN '2008-2018'\n",
    "        ELSE 'OTHER'\n",
    "        END AS 'GRAD_YEAR_GROUP'   \n",
    "    ,Physicians_unique.Number_of_Group_Practice_members\n",
    "    ,state_reference.state_region\n",
    "    ,zip_reference.rural_urban_class\n",
    "    ,zip_reference.zip_land_area_2010\n",
    "    ,zip_reference.zip_population_density_2010\n",
    "    ,zip_reference.zip_population_2010\n",
    "FROM npi_summary\n",
    "    LEFT JOIN Physicians_unique\n",
    "        ON npi_summary.npi = Physicians_unique.npi\n",
    "    LEFT JOIN state_reference\n",
    "        ON state_reference.nppes_provider_state = npi_summary.nppes_provider_state\n",
    "    LEFT JOIN zip_reference\n",
    "        ON zip_reference.zip = npi_summary.nppes_provider_zip5              \n",
    "WHERE Physicians_unique.NPI is not null\n",
    "    AND opioid_day_supply <> '0' \n",
    "    AND opioid_day_supply <> '';\n",
    "\"\"\")\n",
    "\n",
    "# read from the main table\n",
    "df = pd.read_sql_query(\n",
    "    sql,\n",
    "    conn\n",
    ")\n",
    "\n",
    "df['log_opioid_day_supply'] = np.log(df['opioid_day_supply'])\n",
    "\n",
    "# replace missing valaues related to zip with mean\n",
    "df_model['zip_population_2010'].fillna((df_model['zip_population_2010'].mean()), inplace=True)\n",
    "df_model['zip_land_area_2010'].fillna((df_model['zip_land_area_2010'].mean()), inplace=True)\n",
    "df_model['zip_population_density_2010'].fillna((df_model['zip_population_density_2010'].mean()), inplace=True)\n",
    "\n",
    "# take a sample for analysis / modeling\n",
    "df_model = df.sample(frac=.3)\n",
    "\n",
    "# quick summary\n",
    "print(f'dataframe dimensions: {df_model.shape}')\n",
    "print(f'column names: {df_model.columns}')\n",
    "print(f' column types: {df_model.dtypes}')\n",
    "\n",
    "# set index to npi\n",
    "df_model = df_model.set_index('npi')\n",
    "\n",
    "# columns that we cannot use for modeling\n",
    "drop_cols = [\n",
    "    'opioid_claim_count',\n",
    "    'opioid_bene_count',\n",
    "    'opioid_prescriber_rate',\n",
    "    'opioid_day_supply',\n",
    "]\n",
    "\n",
    "df_model.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# format columns to numeric\n",
    "for i in df_model.columns:\n",
    "    if df_model[i].dtype == object:\n",
    "        df_model[i] = df_model[i].apply(\n",
    "            lambda x: 0 if x == '' else x\n",
    "        )\n",
    "\n",
    "# clean credentials into usable meta groups\n",
    "df_model = clean_credentials(df_model)\n",
    "df_model.drop('nppes_credentials', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# list of categorical columns\n",
    "cols_to_dummy = [\n",
    "    'nppes_provider_gender', \n",
    "    'nppes_provider_city',\n",
    "    'nppes_provider_state',\n",
    "    'nppes_provider_country',\n",
    "    'specialty_description',\n",
    "    'GRAD_YEAR_GROUP',\n",
    "    'state_region',\n",
    "    'rural_urban_class'\n",
    "]\n",
    "\n",
    "# dummy out the categorical columns\n",
    "df_model = dummy_wrapper(df_model, cols_to_dummy)\n",
    "\n",
    "# variance filter\n",
    "df_model = variance_threshold(df_model, threshold=.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA \n",
    "\n",
    "# distribution of target\n",
    "plt.style.use(['dark_background'])\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "sns.kdeplot(df_model['opioid_prescriber_rate'])\n",
    "plt.show()\n",
    "\n",
    "# TODO: box plots of categorical to target\n",
    "\n",
    "# scatterplot risk score to rate\n",
    "sns.scatterplot(\n",
    "    'beneficiary_average_risk_score',\n",
    "    'opioid_prescriber_rate',\n",
    "    data=df_model.sample(frac=.01)\n",
    ").set_title('Opioid Prescriber Rate vs. Risk Score')\n",
    "plt.show()\n",
    "\n",
    "# scatterplot total claim to rate\n",
    "sns.scatterplot(\n",
    "    np.log(df_model['total_claim_count']),\n",
    "    'opioid_prescriber_rate',\n",
    "    data=df_model.sample(frac=.01)\n",
    ").set_title('Opioid Prescriber Rate vs. Total Claim Count')\n",
    "plt.show()\n",
    "\n",
    "# scatterplot avg age to rate\n",
    "sns.scatterplot(\n",
    "    'average_age_of_beneficiaries',\n",
    "    'opioid_prescriber_rate',\n",
    "    data=df_model.sample(frac=.01)\n",
    ").set_title('Opioid Prescriber Rate vs. Average Beneficiary Age')\n",
    "plt.show()\n",
    "\n",
    "# correlation matrix - spearman\n",
    "corr = pd.DataFrame(df_model.corr(method='spearman'))\n",
    "\n",
    "# print heatmap of correlation matrix all features\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr, cbar=False, cmap='YlGnBu').set_title(\n",
    "    'Correlation Matrix: Full Feature Set'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# correlation matrix - key features - spearman\n",
    "corr_subset = pd.DataFrame(\n",
    "    df_model.loc[:, 'total_claim_count':'beneficiary_average_risk_score']\n",
    "    .corr(method='spearman')\n",
    ")\n",
    "\n",
    "# print heatmap of correlation matrix select features\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(\n",
    "    corr_subset, cbar=False, cmap='YlGnBu', annot=True\n",
    "    ).set_title('Correlation Matrix: Select Feature Set')\n",
    "plt.show()\n",
    "\n",
    "# distribution of opioid day supply\n",
    "sns.distplot(df['opioid_day_supply']).set_title('Distribution of Opioid Day Supply - full file')\n",
    "plt.savefig('opioid_day_supply.png')\n",
    "\n",
    "# distribution of log opioid day supply\n",
    "sns.distplot(df['log_opioid_day_supply']).set_title('Distribution of Log Opioid Day Supply - full file')\n",
    "plt.savefig('log_opioid_day_supply.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL\n",
    "# set up train/test \n",
    "\n",
    "# divide data into target and predictors\n",
    "model_target = 'log_opioid_day_supply'\n",
    "op_target = df_model[model_target].values\n",
    "op_features = df_model.drop(model_target, axis=1)\n",
    "\n",
    "# set up test and train\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    op_features,\n",
    "    op_target,\n",
    "    test_size=.3,\n",
    "    shuffle=True,\n",
    "    random_state=789651244\n",
    ")\n",
    "\n",
    "# initialize the gbm \n",
    "op_gbm = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    loss='lad',\n",
    "    max_depth=200,\n",
    "    max_features='sqrt',\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=.05,\n",
    "    min_samples_split=.05,\n",
    "    n_estimators=200,\n",
    "    presort='auto',\n",
    "    random_state=758491629,\n",
    "    subsample=0.3,\n",
    "    verbose=10,\n",
    "    warm_start=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL\n",
    "# set up bayesian grid search\n",
    "opt = skopt.BayesSearchCV(\n",
    "    op_gbm,\n",
    "    {\n",
    "        \"learning_rate\": (1e-8, .98, 'log-uniform'),\n",
    "        \"max_depth\": (1, 300),\n",
    "        \"n_estimators\": (20, 200),\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"subsample\": (0.3, .9, 'log-uniform'),\n",
    "        \"min_samples_split\": (.005, .1),\n",
    "        \"min_samples_leaf\": (.005, .1)\n",
    "    },\n",
    "    n_iter=40,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "# fit parameters\n",
    "op_opt_gbm = opt.fit(x_train, y_train)\n",
    "\n",
    "# cross validate the bayesian optimized gbm model\n",
    "cross_validate(\n",
    "    op_opt_gbm,\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "# show the best params\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(opt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL\n",
    "# initialize the gbm regressor\n",
    "op_gbm_bayes = GradientBoostingRegressor(\n",
    "    alpha=0.9, criterion='friedman_mse', init=None,\n",
    "    learning_rate=0.15066211175185815, loss='lad', max_depth=203,\n",
    "    max_features='log2', max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "    min_samples_leaf=0.005, min_samples_split=0.005,\n",
    "    min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "    presort='auto', random_state=758491629, subsample=0.9,\n",
    "    verbose=10, warm_start=False\n",
    ")\n",
    "\n",
    "# fit the regressor\n",
    "op_gbm_bayes_fit = op_gbm_bayes.fit(x_train, y_train)\n",
    "\n",
    "# cross validate the gbm model\n",
    "cross_validate(\n",
    "    op_gbm_bayes_fit,\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    cv=10,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "# extract variable importance for the gbm model\n",
    "df_vimp, vimp_columns = extract_vimp(\n",
    "    op_gbm_bayes_fit,\n",
    "    column_names=x_train,\n",
    "    threshold=.004\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot variable importance\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "sns.barplot(\n",
    "    x='tree_vimp',\n",
    "    y='variable',\n",
    "    data=df_vimp\n",
    ").set_title('Variable Importance: Bayesian Gradient Boosting')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# get model train predictions\n",
    "y_pred = op_gbm_bayes_fit.predict(x_train)\n",
    "print(f'train predictions mean {np.mean(y_pred)}')\n",
    "print(f'train predictions median {np.median(y_pred)}')\n",
    "print(f'train predictions var {np.var(y_pred)}')\n",
    "\n",
    "# plot predictions distribution\n",
    "sns.distplot(y_pred).set_title('Train Predictions Distribution')\n",
    "plt.show()\n",
    "\n",
    "# plot predictions vs. actuals - train set\n",
    "sns.scatterplot(\n",
    "    x=y_pred,\n",
    "    y=y_train\n",
    ").set_title('Opioid Rate Predictions vs. Train')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('train actuals')\n",
    "plt.show()\n",
    "\n",
    "# put train predictions and actuals together\n",
    "df_comb = pd.concat([pd.Series(y_pred), pd.Series(y_train)], axis=1)\n",
    "df_comb.columns = ['predictions', 'actuals']\n",
    "\n",
    "# get difference\n",
    "df_comb['error'] = np.abs(df_comb['predictions'] - df_comb['actuals'])\n",
    "\n",
    "# plot predictions vs. actuals - train set\n",
    "sns.scatterplot(\n",
    "    x='predictions',\n",
    "    y='actuals',\n",
    "    data=df_comb.sample(frac=.3),\n",
    "    hue='error'\n",
    ").set_title('Opioid Rate Predictions vs. Train')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('train actuals')\n",
    "plt.show()\n",
    "\n",
    "# get model test predictions\n",
    "y_pred_test = op_gbm_bayes_fit.predict(x_test)\n",
    "print(f'test predictions mean {np.mean(y_pred_test)}')\n",
    "print(f'test predictions median {np.median(y_pred_test)}')\n",
    "print(f'test predictions var {np.var(y_pred_test)}')\n",
    "\n",
    "# plot predictions distribution\n",
    "sns.distplot(y_pred_test).set_title('Test Predictions Distribution')\n",
    "plt.show()\n",
    "\n",
    "# plot predictions vs. actuals - train set\n",
    "sns.scatterplot(\n",
    "    x=y_pred_test,\n",
    "    y=y_test\n",
    ").set_title('Opioid Rate Predictions vs. Test')\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"Actuals\")\n",
    "plt.show()\n",
    "\n",
    "# put train predictions and actuals together\n",
    "df_comb = pd.concat([pd.Series(y_pred_test), pd.Series(y_test)], axis=1)\n",
    "df_comb.columns = ['predictions', 'actuals']\n",
    "\n",
    "# get difference\n",
    "df_comb['error'] = np.abs(df_comb['predictions'] - df_comb['actuals'])\n",
    "\n",
    "# plot predictions vs. actuals - train set\n",
    "sns.scatterplot(\n",
    "    x='predictions',\n",
    "    y='actuals',\n",
    "    data=df_comb.sample(frac=.3),\n",
    "    hue='error',\n",
    "    size='error'\n",
    ").set_title('Opioid Rate Predictions vs. Test')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('train actuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: shap values\n",
    "# TODO: transformation functions for predicting on entire data set\n",
    "# TODO: output frames for plotting shap, residuals\n",
    "# TODO: output final model for predicting on entire dataset\n",
    "\n",
    "# final model to production\n",
    "pickle.dump(\n",
    "    op_gbm_bayes_fit,\n",
    "    open('opioid_gbm_full.sav', 'wb')\n",
    ")\n",
    "\n",
    "# final features to production\n",
    "pickle.dump(\n",
    "    x_train.columns,\n",
    "    open('opioid_features.sav', 'wb')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
